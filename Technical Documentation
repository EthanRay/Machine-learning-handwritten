1 LeNet-5模型
本文实现手写数字识别，使用的是卷积神经网络，建模思想来自LeNet-5
这是原始的应用于手写数字识别的网络，我认为这也是最简单的深度网络。

LeNet-5不包括输入，一共7层，较低层由卷积层和最大池化层交替构成，更高层则是全连接和高斯连接。

LeNet-5的输入与BP神经网路的不一样。这里假设图像是黑白的，那么LeNet-5的输入是一个32*32的二维矩阵。同时，输入与下一层并不是全连接的，而是进行稀疏连接。
本层每个神经元的输入来自于前一层神经元的局部区域(5×5)，卷积核对原始图像卷积的结果加上相应的阈值，得出的结果再经过激活函数处理，输出即形成卷积层（C层）。
卷积层中的每个特征映射都各自共享权重和阈值，这样能大大减少训练开销。降采样层（S层）为减少数据量同时保存有用信息，进行亚抽样。

第一个卷积层（C1层）由6个特征映射构成，每个特征映射是一个28×28的神经元阵列，其中每个神经元负责从5×5的区域通过卷积滤波器提取局部特征
。一般情况下，滤波器数量越多，就会得出越多的特征映射，反映越多的原始图像的特征。
本层训练参数共6×(5×5+1)=156个，每个像素点都是由上层5×5=25个像素点和1个阈值连接计算所得，共28×28×156=122304个连接。

S2层是对应上述6个特征映射的降采样层（pooling层）。pooling层的实现方法有两种，分别是max-pooling和mean-pooling，LeNet-5采用的是mean-pooling，
即取n×n区域内像素的均值。C1通过2×2的窗口区域像素求均值再加上本层的阈值，然后经过激活函数的处理，得到S2层。pooling的实现，在保存图片信息的基础上，
减少了权重参数，降低了计算成本，还能控制过拟合。本层学习参数共有1*6+6=12个，S2中的每个像素都与C1层中的2×2个像素和1个阈值相连，共6×(2×2+1)×14×14=5880个连接。

S2层和C3层的连接比较复杂。C3卷积层是由16个大小为10×10的特征映射组成的，当中的每个特征映射与S2层的若干个特征映射的局部感受野（大小为5×5）相连。
其中，前6个特征映射与S2层连续3个特征映射相连，后面接着的6个映射与S2层的连续的4个特征映射相连，然后的3个特征映射与S2层不连续的4个特征映射相连，
最后一个映射与S2层的所有特征映射相连。此处卷积核大小为5×5，所以学习参数共有6×(3×5×5+1)+9×(4×5×5+1)+1×(6×5×5+1)=1516个参数。而图像大小为28×28，因此共有151600个连接。

S4层是对C3层进行的降采样，与S2同理，学习参数有16×1+16=32个，同时共有16×(2×2+1)×5×5=2000个连接。

C5层是由120个大小为1×1的特征映射组成的卷积层，而且S4层与C5层是全连接的，因此学习参数总个数为120×(16×25+1)=48120个。

F6是与C5全连接的84个神经元，所以共有84×(120+1)=10164个学习参数。

卷积神经网络通过通过稀疏连接和共享权重和阈值，大大减少了计算的开销，同时，pooling的实现，一定程度上减少了过拟合问题的出现，非常适合用于图像的处理和识别。
2 手写数字识别算法模型的构建
Sigmoid函数具有光滑性、鲁棒性和其导数可用自身表示的优点，但其运算涉及指数运算，反向传播求误差梯度时，求导又涉及乘除运算，计算量相对较大。
同时，针对本文构建的含有两层卷积层和降采样层，由于sgmoid函数自身的特性，在反向传播时，很容易出现梯度消失的情况，从而难以完成网络的训练。
因此，本文设计的网络使用ReLU函数作为激活函数
使用Python，调用Tendorflow的api完成手写数字识别的算法。
